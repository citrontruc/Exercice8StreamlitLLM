import streamlit as st
from helper.conversation_agent import ConversationAgent
from helper.ui_helper import UIHelper

st.sidebar.markdown("Interrogez vos donnÃ©es ğŸ•µï¸â€â™€ï¸")
st.sidebar.markdown("Permet d'interroger les donnÃ©es prÃ©sentes dans le dossier data.")

st.title("Interrogez vos donnÃ©es ğŸ•µï¸â€â™€ï¸")
st.markdown("""
Ce modÃ¨le interroge les rÃ¨gles de base du jeu donjons et dragons, disponibles Ã  [cette adresse](https://www.aidedd.org/adj/telechargement/).
Il possÃ¨de les rÃ¨gles en franÃ§ais et rÃ©pondra donc sans doute mieux aux questions en franÃ§ais.
        
""")

pdf_uiagent = UIHelper("ğŸ•µï¸â€â™€ï¸")
competency_analysis_agent = ConversationAgent()

# The messages between user and assistant are kept in the session_state (the local storage)
if "message_hist" not in st.session_state:
    st.session_state.message_hist = []

# Message de bienvenue Ã  l'utilisateur et bouton "nouveau chat"
pdf_uiagent.reset_button()

# Affichage de l'historique des messages
if st.session_state.message_hist == []:
    pdf_uiagent.initialize_conv(competency_analysis_agent.random_intro())
else:
    pdf_uiagent.show_conversation(st.session_state.message_hist)

# This is the user's textbox for chatting with the assistant
if prompt := st.chat_input("Quelle est votre question ?"):
    # Lors de la rÃ©ception d'un message, on affiche le message, on rÃ©cupÃ¨re la rÃ©ponse et on l'affiche Ã  l'Ã©cran.
    pdf_uiagent.format_user_question(prompt)
    streamed_response = competency_analysis_agent.answer_rag(
            message_hist=st.session_state.message_hist[-2:], 
            user_question = prompt
        )
    full_str_reponse = pdf_uiagent.format_llm_response(streamed_response)

    # On met Ã  jour notre historique de messages
    st.session_state.message_hist.append({"role": "user", "content": prompt})
    st.session_state.message_hist.append({"role": "assistant", "content": full_str_reponse})