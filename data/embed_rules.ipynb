{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But du notebook\n",
    "\n",
    "Le but de ce notebook est de récupérer le texte des règles de donjons et dragons pour ensuite en faire un embedding que l'on pourra ensuite interroger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération de notre pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"Basic-Rules-FR.pdf\")\n",
    "embedding_model = SentenceTransformer(\"distiluse-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction du texte des pages.\n",
    "\n",
    "On ne récupère pas les pieds de pages car ils contiennent le numéro de la page et l'adresse du site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = []\n",
    "\n",
    "# Fonction pour exclure les pieds de pages\n",
    "def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "    y = tm[5]\n",
    "    if y > 50 and y < 500:\n",
    "        parts.append(text)\n",
    "\n",
    "for i in tqdm(range(len(reader.pages))):\n",
    "    parts.append(reader.pages[i].extract_text()[37:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pdf_text = \" \".join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding de notre texte\n",
    "\n",
    "En vue d'interroger ce texte par un modèle de deep learning, il faut en faire un embedding. On pourrait le faire tout simplement par chunks de 1024 caractères mais on voudrait faire quelque chose de plus subtil.\n",
    "\n",
    "Possibilités :\n",
    "- Séparer par phrases.\n",
    "- Mettre du recouvrement entre chunks.\n",
    "- Regrouper les phrases par leur sémantique. (On faite un embedding des phrases et on fusionne les phrases qui possèdent un embedding proche).\n",
    "\n",
    "Afin de concilier puissance et vitesse d'exécution, nous allons faire des groupes de plusieurs phrases (dans un maximum de 1024 caractères) avec une phrase de chevauchement.\n",
    "\n",
    "**Note** : Afin d'améliorer notre séparation, nous aurions pu tenir compte des paragraphes. A faire éventuellement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en forme du document et suppression du sommaire\n",
    "sentence_list = re.split('\\\\. |\\\\! |\\\\? ', full_pdf_text)\n",
    "useful_sentences = sentence_list[343:]\n",
    "for i in range(len(useful_sentences)):\n",
    "    useful_sentences[i] = useful_sentences[i].replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regroupe nos phrases dans une limite de 1024 caractères.\n",
    "# On élimine les phrases trop longues car elles correspondent plutôt à des morceaux mal coupés (liste de sorts)\n",
    "\n",
    "chunk_list = []\n",
    "current_chunk = \"\"\n",
    "threshold = 1024\n",
    "i=0\n",
    "\n",
    "useful_sentences = [element for element in useful_sentences if len(element) < 400]\n",
    "while i < len(useful_sentences):\n",
    "    accept_new_sentence = (len(current_chunk) + len(useful_sentences[i])) < threshold\n",
    "    if accept_new_sentence:\n",
    "        current_chunk = current_chunk + \". \" + useful_sentences[i]\n",
    "    else:\n",
    "        chunk_list.append(current_chunk)\n",
    "        current_chunk = \"\"\n",
    "        if i > 0:\n",
    "            current_chunk += useful_sentences[i-1] + \". \" + useful_sentences[i]\n",
    "        else:\n",
    "            current_chunk += useful_sentences[i]\n",
    "    i+=1\n",
    "\n",
    "chunk_list.append(current_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait l'embedding proprement dit.\n",
    "embedding_data = embedding_model.encode(chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dataframe = pd.DataFrame({\"text_chunk\" : chunk_list})\n",
    "embedding_dataframe.to_csv(\"text_rag.csv\", sep=\";\", index=False)\n",
    "np.save(\"vector_rag.npy\", embedding_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
